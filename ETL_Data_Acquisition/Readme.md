# ETL Pipeline - Gans E-Scooter Case Study

## Project Overview

Gans is a fictive innovative startup developing an e-scooter-sharing system aiming to operate in major cities worldwide. The task was to build an ETL (Extract, Transform, Load) pipeline that will collect, clean, and store data to help predict e-scooter movement patterns and predict potential customer use.

## Business Context

E-scooter companies, including competitors like TIER and Bird, emphasize sustainable mobility. However, Gans has identified that operational success relies heavily on efficient scooter distribution. Several factors contribute to scooter usage asymmetries, such as:

- Users riding uphill but walking downhill in hilly cities.
- Morning migrations from residential areas to city centers.
- Reduced usage during rainy conditions.
- Tourists requiring scooters near landmarks and downtown areas.

To address these issues, Gans can either relocate scooters via trucks or offer incentives for users to pick up or drop off scooters in specific areas. To make informed decisions, the company needs accurate and comprehensive data, which is where this project comes in.

## Project Scope

This project focuses on building a local ETL pipeline to extract data from various sources, process it, and store it in an SQL database. The key objectives include:

## Data Collection

- Web Scraping: Extracting relevant data from publicly accessible websites > Wikipedia.
- APIs: Accessing structured data from external services > .

## Data Transformation

Cleaning and structuring data using Python and pandas.

## Data Storage

Storing transformed data in an SQL database for easy access and analysis.

## Technologies Used

- Python (for scripting and data processing)
- pandas (for data transformation and cleaning)
- BeautifulSoup (for web scraping)
- API integration (for structured data retrieval)
- SQL (for data storage and querying)

## Key Challenges & Learnings

Throughout this project, several challenges were tackled, including:

- Managing inconsistent data formats from different sources.
- Handling authentication for API access.
- Ensuring ethical and responsible web scraping practices.

## Deliverable

The final deliverable is a fully functional ETL pipeline, with all files uploaded to this GitHub repository.

## What This Project Does NOT Cover

To maintain clarity and focus, the following aspects are intentionally out of scope:

- Integration with BI tools for visualization.
- Development of a data warehouse or data lake.
- Handling big data, streaming data, or parallel computing.

## Conclusion

This project is a testament to data engineering skills, showcasing proficiency in data extraction, transformation, and storage. By developing this ETL pipeline, I take the first step towards predictive analytics for efficient scooter management.

Feel free to explore the code and provide feedback. ðŸš€



